hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vvHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torchHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# 🩸 *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## 🔧 Project Structure

```
hemato-vision/
│
├── data/                         # Dataset folder
│   ├── raw/                     # Original dataset
│   ├── processed/               # Preprocessed dataset
│
├── notebooks/                   # Jupyter notebooks for EDA & experiments
│   └── eda.ipynb
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── config.py                # Configuration (paths, hyperparameters)
│   ├── data_loader.py           # Data loading and preprocessing
│   ├── model.py                 # Transfer learning model definition
│   ├── train.py                 # Training logic
│   ├── evaluate.py              # Evaluation logic
│   └── utils.py                 # Helper functions
│
├── outputs/
│   ├── models/                  # Saved models
│   ├── logs/                    # Training logs
│   └── reports/                 # Evaluation reports and graphs
│
├── tests/                       # Unit tests
│   └── test_data_loader.py
│
├── requirements.txt             # Python dependencies
├── train.py                     # CLI to start training
├── inference.py                 # Script for inference on new images
└── README.md
```

---

## 💻 Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## 🧪 Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## 📦 `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## 📝 README Highlights

````markdown
# 🩸 HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
