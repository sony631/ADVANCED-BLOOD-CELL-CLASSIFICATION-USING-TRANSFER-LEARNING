hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vvHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torchHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```

import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
vHere's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
Here's a detailed **project structure** and **coding outline** for a project titled:

# ğŸ©¸ *HemaTo Vision: Advanced Blood Cell Classification using Transfer Learning*

---

## ğŸ”§ Project Structure

```
hemato-vision/
â”‚
â”œâ”€â”€ data/                         # Dataset folder
â”‚   â”œâ”€â”€ raw/                     # Original dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & experiments
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration (paths, hyperparameters)
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Transfer learning model definition
â”‚   â”œâ”€â”€ train.py                 # Training logic
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation logic
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ reports/                 # Evaluation reports and graphs
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train.py                     # CLI to start training
â”œâ”€â”€ inference.py                 # Script for inference on new images
â””â”€â”€ README.md
```

---

## ğŸ’» Core Code

Below is a simplified version of each key component:

---

### `src/config.py`

```python
import os

class Config:
    DATA_DIR = "data/processed"
    MODEL_DIR = "outputs/models"
    IMG_SIZE = 224
    BATCH_SIZE = 32
    NUM_CLASSES = 5  # e.g. neutrophil, eosinophil, etc.
    EPOCHS = 20
    LR = 1e-4
    DEVICE = "cuda"  # or "cpu"
```

---

### `src/data_loader.py`

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from src.config import Config

def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/train", transform=transform)
    val_dataset = datasets.ImageFolder(root=f"{Config.DATA_DIR}/val", transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader
```

---

### `src/model.py`

```python
import torch.nn as nn
from torchvision import models
from src.config import Config

def get_model():
    base_model = models.resnet18(pretrained=True)
    for param in base_model.parameters():
        param.requires_grad = False  # freeze
    
    # Replace classifier head
    num_features = base_model.fc.in_features
    base_model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, Config.NUM_CLASSES)
    )
    
    return base_model
```

---

### `src/train.py`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from src.config import Config
from src.data_loader import get_dataloaders
from src.model import get_model

def train():
    device = torch.device(Config.DEVICE)
    model = get_model().to(device)
    train_loader, val_loader = get_dataloaders()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    for epoch in range(Config.EPOCHS):
        model.train()
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{Config.EPOCHS}, Loss: {total_loss:.4f}")
    
    torch.save(model.state_dict(), f"{Config.MODEL_DIR}/resnet18_blood.pth")
```

---

### `train.py` (entry point)

```python
from src.train import train

if __name__ == "__main__":
    train()
```

---

### `inference.py`

```python
import torch
from torchvision import transforms
from PIL import Image
from src.model import get_model
from src.config import Config

def predict(image_path):
    device = torch.device(Config.DEVICE)
    model = get_model()
    model.load_state_dict(torch.load(f"{Config.MODEL_DIR}/resnet18_blood.pth"))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor()
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(image)
        _, pred = torch.max(outputs, 1)
    
    class_names = ['neutrophil', 'eosinophil', 'basophil', 'lymphocyte', 'monocyte']
    print(f"Predicted: {class_names[pred.item()]}")
```

---

## ğŸ§ª Sample Test File: `tests/test_data_loader.py`

```python
from src.data_loader import get_dataloaders

def test_loader():
    train_loader, val_loader = get_dataloaders()
    assert len(train_loader) > 0
    assert len(val_loader) > 0
```

---

## ğŸ“¦ `requirements.txt`

```
torch
torchvision
matplotlib
numpy
pillow
scikit-learn
```

---

## ğŸ“ README Highlights

````markdown
# ğŸ©¸ HemaTo Vision

Advanced blood cell classification using Transfer Learning (ResNet18).

## Features
- Image classification for 5 types of white blood cells
- Uses PyTorch and pre-trained ResNet18
- Easy training and inference scripts

## Usage

### Train
```bash
python train.py
````

### Inference

```bash
python inference.py --image path_to_image.jpg
```

```

---

Would you like help customizing this for a specific dataset (e.g., **BCCD**, **LISC**, or **BloodMNIST**) or deploying it (e.g., **Flask API** or **Streamlit app**)?

```
